{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\artur\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import h5py\n",
    "import scipy\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações para o treinamento\n",
    "train_data_dir = './data'\n",
    "batch_size = 40 # imagens por lote\n",
    "num_epochs = 75 # épocas de treinamento\n",
    "image_size = (200, 200) # tamanho imagens\n",
    "num_classes = 5 # qtd de classes\n",
    "classes = ['Raiva', 'Alegria', 'Neutro', 'Triste', 'Surpresa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_in_color(txt_msg,fore_tupple,back_tupple,):\n",
    "    #prints the text_msg in the foreground color specified by fore_tupple with the background specified by back_tupple \n",
    "    #text_msg is the text, fore_tupple is foregroud color tupple (r,g,b), back_tupple is background tupple (r,g,b)\n",
    "    rf,gf,bf=fore_tupple\n",
    "    rb,gb,bb=back_tupple\n",
    "    msg='{0}' + txt_msg\n",
    "    mat='\\33[38;2;' + str(rf) +';' + str(gf) + ';' + str(bf) + ';48;2;' + str(rb) + ';' +str(gb) + ';' + str(bb) +'m' \n",
    "    print(msg .format(mat), flush=True)\n",
    "    print('\\33[0m', flush=True) # returns default print color to back to black\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRA(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,model, base_model, patience,stop_patience, threshold, factor, dwell, batches, initial_epoch,epochs, ask_epoch, csv_path=None):\n",
    "        super(LRA, self).__init__()\n",
    "        self.model=model\n",
    "        self.base_model=base_model\n",
    "        self.patience=patience # especifica quantas épocas sem melhoria antes que a taxa de aprendizado seja ajustada\n",
    "        self.stop_patience=stop_patience # especifica quantas vezes ajustar a taxa de aprendizado sem melhoria para parar o treinamento\n",
    "        self.threshold=threshold # especifica o limiar de acurácia de treinamento quando a taxa de aprendizado será ajustada com base na perda de validação\n",
    "        self.factor=factor # fator pelo qual reduzir a taxa de aprendizado\n",
    "        self.dwell=dwell\n",
    "        self.batches=batches # número de lotes de treinamento para executar por época\n",
    "        self.initial_epoch=initial_epoch\n",
    "        self.epochs=epochs\n",
    "        self.ask_epoch=ask_epoch\n",
    "        self.ask_epoch_initial=ask_epoch # salvar este valor para restaurar se reiniciar o treinamento\n",
    "        self.csv_path=csv_path\n",
    "        # variáveis de callback\n",
    "        self.count=0 # quantas vezes a taxa de aprendizado foi reduzida sem melhoria\n",
    "        self.stop_count=0\n",
    "        self.best_epoch=1 # época com a menor perda\n",
    "        self.initial_lr=float(tf.keras.backend.get_value(model.optimizer.lr)) # obter a taxa de aprendizado inicial e salvá-la\n",
    "        self.highest_tracc=0.0 # definir a maior acurácia de treinamento inicialmente como 0\n",
    "        self.lowest_vloss=np.inf # definir a menor perda de validação inicialmente como infinito\n",
    "        self.best_weights=self.model.get_weights() # definir os melhores pesos como os pesos iniciais do modelo\n",
    "        self.initial_weights=self.model.get_weights() # salvar os pesos iniciais caso precisem ser restaurados\n",
    "        self.data_dict={}\n",
    "        for key in ['epoch','tr loss','tr acc','vloss','vacc','current lr','next lr','monitor','% improv','duration']:\n",
    "            self.data_dict[key]=[]\n",
    "    def on_train_begin(self, logs=None):\n",
    "        if self.base_model != None:\n",
    "            status=base_model.trainable\n",
    "            if status:\n",
    "                msg=' inicializando callback iniciando treinamento com base_model treinável'\n",
    "            else:\n",
    "                msg='inicializando callback iniciando treinamento com base_model não treinável'\n",
    "        else:\n",
    "            msg='inicializando callback e iniciando treinamento'\n",
    "        print_in_color (msg, (244, 252, 3), (55,65,80))\n",
    "        msg='{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^9s}{6:^9s}{7:^10s}{8:10s}{9:^8s}'.format('Epoch', 'Loss', 'Accuracy', 'V_loss','V_acc', 'LR', 'Next LR', 'Monitor','% Improv', 'Duration')\n",
    "        print_in_color(msg, (244,252,3), (55,65,80))\n",
    "        self.start_time= time.time()\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        stop_time=time.time()\n",
    "        tr_duration= stop_time- self.start_time            \n",
    "        hours = tr_duration // 3600\n",
    "        minutes = (tr_duration - (hours * 3600)) // 60\n",
    "        seconds = tr_duration - ((hours * 3600) + (minutes * 60))\n",
    "        if self.csv_path !=None:\n",
    "            df=pd.DataFrame.from_dict(self.data_dict)\n",
    "            now = datetime.now() \n",
    "            year = str(now.year)\n",
    "            month=str(now.month)\n",
    "            day=str(now.day)\n",
    "            hour=str(now.hour)\n",
    "            minute=str(now.minute)\n",
    "            sec=str(now.second)\n",
    "            label = month + '-'+ day + '-' + year + '-' + hour + '-' + minute + '-' + sec +'.csv'\n",
    "            csv_path=self.csv_path + '-'+ label\n",
    "            df.to_csv(csv_path, index=False) \n",
    "            print('dados de treinamento salvos como ', csv_path)\n",
    "\n",
    "        self.model.set_weights(self.best_weights) # definir os pesos do modelo para os melhores pesos\n",
    "        msg=f'Treinamento concluído - modelo definido com pesos da época {self.best_epoch} '\n",
    "        print_in_color(msg, (0,255,0), (55,65,80))\n",
    "        msg = f'o tempo decorrido de treinamento foi {str(hours)} horas, {minutes:4.1f} minutos, {seconds:4.2f} segundos'\n",
    "        print_in_color(msg, (0,255,0), (55,65,80))   \n",
    "        \n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        acc=logs.get('accuracy')* 100  # obter a acurácia de treinamento \n",
    "        loss=logs.get('loss')\n",
    "        msg='{0:20s}processando lote {1:4s} de {2:5s} acurácia= {3:8.3f}  perda: {4:8.5f}'.format(' ', str(batch), str(self.batches), acc, loss)\n",
    "        print(msg, '\\r', end='') # imprime na mesma linha para mostrar a contagem de lotes em execução        \n",
    "        \n",
    "    def on_epoch_begin(self,epoch, logs=None):\n",
    "        self.now= time.time()\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):  # método executado no final de cada época\n",
    "        later=time.time()\n",
    "        duration=later-self.now \n",
    "        lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) # obter a taxa de aprendizado atual\n",
    "        current_lr=lr\n",
    "        v_loss=logs.get('val_loss')  # obter a perda de validação para esta época\n",
    "        acc=logs.get('accuracy')  # obter a acurácia de treinamento \n",
    "        v_acc=logs.get('val_accuracy')\n",
    "        loss=logs.get('loss')        \n",
    "        if acc < self.threshold: # se a acurácia de treinamento estiver abaixo do limiar, ajustar a taxa de aprendizado com base na acurácia de treinamento\n",
    "            monitor='accuracy'\n",
    "            if epoch ==0:\n",
    "                pimprov=0.0\n",
    "            else:\n",
    "                pimprov= (acc-self.highest_tracc )*100/self.highest_tracc\n",
    "            if acc>self.highest_tracc: # a acurácia de treinamento melhorou na época                \n",
    "                self.highest_tracc=acc # definir nova maior acurácia de treinamento\n",
    "                self.best_weights=self.model.get_weights() # a acurácia de treinamento melhorou, então salvar os pesos\n",
    "                self.count=0 # definir contagem para 0 já que a acurácia de treinamento melhorou\n",
    "                self.stop_count=0 # definir contador de paradas para 0\n",
    "                if v_loss<self.lowest_vloss:\n",
    "                    self.lowest_vloss=v_loss\n",
    "                color= (0,255,0)\n",
    "                self.best_epoch=epoch + 1  # definir o valor da melhor época para esta época              \n",
    "            else: \n",
    "                # a acurácia de treinamento não melhorou, verificar se isso aconteceu por um número de épocas igual à paciência\n",
    "                # se sim, ajustar a taxa de aprendizado\n",
    "                if self.count>=self.patience -1: # a taxa de aprendizado deve ser ajustada\n",
    "                    color=(245, 170, 66)\n",
    "                    lr= lr* self.factor # ajustar a taxa de aprendizado pelo fator\n",
    "                    tf.keras.backend.set_value(self.model.optimizer.lr, lr) # definir a taxa de aprendizado no otimizador\n",
    "                    self.count=0 # redefinir a contagem para 0\n",
    "                    self.stop_count=self.stop_count + 1 # contar o número de ajustes consecutivos da taxa de aprendizado\n",
    "                    self.count=0 # redefinir contador\n",
    "                    if self.dwell:\n",
    "                        self.model.set_weights(self.best_weights) # retornar a um ponto melhor no espaço N                        \n",
    "                    else:\n",
    "                        if v_loss<self.lowest_vloss:\n",
    "                            self.lowest_vloss=v_loss                                    \n",
    "                else:\n",
    "                    self.count=self.count +1 # incrementar contador de paciência                    \n",
    "        else: # a acurácia de treinamento está acima do limiar, então ajustar a taxa de aprendizado com base na perda de validação\n",
    "            monitor='val_loss'\n",
    "            if epoch ==0:\n",
    "                pimprov=0.0\n",
    "            else:\n",
    "                pimprov= (self.lowest_vloss- v_loss )*100/self.lowest_vloss\n",
    "            if v_loss< self.lowest_vloss: # verificar se a perda de validação melhorou \n",
    "                self.lowest_vloss=v_loss # substituir a menor perda de validação pela nova perda de validação                \n",
    "                self.best_weights=self.model.get_weights() # a perda de validação melhorou, então salvar os pesos\n",
    "                self.count=0 # redefinir contagem já que a perda de validação melhorou  \n",
    "                self.stop_count=0  \n",
    "                color=(0,255,0)                \n",
    "                self.best_epoch=epoch + 1 # definir o valor da melhor época para esta época\n",
    "            else: # a perda de validação não melhorou\n",
    "                if self.count>=self.patience-1: # é necessário ajustar a taxa de aprendizado\n",
    "                    color=(245, 170, 66)\n",
    "                    lr=lr * self.factor # ajustar a taxa de aprendizado                    \n",
    "                    self.stop_count=self.stop_count + 1 # incrementar contador de paradas porque a taxa de aprendizado foi ajustada \n",
    "                    self.count=0 # redefinir contador\n",
    "                    tf.keras.backend.set_value(self.model.optimizer.lr, lr) # definir a taxa de aprendizado no otimizador\n",
    "                    if self.dwell:\n",
    "                        self.model.set_weights(self.best_weights) # retornar a um ponto melhor no espaço N\n",
    "                else: \n",
    "                    self.count =self.count +1 # incrementar o contador de paciência                    \n",
    "                if acc>self.highest_tracc:\n",
    "                    self.highest_tracc= acc\n",
    "        msg=f'{str(epoch+1):^3s}/{str(self.epochs):4s} {loss:^9.3f}{acc*100:^9.3f}{v_loss:^9.5f}{v_acc*100:^9.3f}{current_lr:^9.5f}{lr:^9.5f}{monitor:^11s}{pimprov:^10.2f}{duration:^8.2f}'\n",
    "        print_in_color (msg,color, (55,65,80))\n",
    "        key_list=['epoch','tr loss','tr acc','vloss','vacc','current lr','next lr','monitor','% improv','duration']\n",
    "        val_list =[epoch + 1, loss, acc, v_loss, v_acc, current_lr, lr, monitor, pimprov, duration]\n",
    "        for key, value in zip(key_list, val_list):\n",
    "            self.data_dict[key].append(value)\n",
    "        \n",
    "        if self.stop_count> self.stop_patience - 1: # verificar se a taxa de aprendizado foi ajustada um número de vezes igual a stop_count sem melhoria\n",
    "            msg=f' o treinamento foi interrompido na época {epoch + 1} após {self.stop_patience} ajustes da taxa de aprendizado sem melhoria'\n",
    "            print_in_color(msg, (0,255,255), (55,65,80))\n",
    "            self.model.stop_training = True # parar o treinamento\n",
    "        else: \n",
    "            if self.ask_epoch !=None:                \n",
    "                if epoch + 1 >= self.ask_epoch:\n",
    "                    if base_model.trainable:\n",
    "                        msg='digite H para interromper o treinamento ou um número inteiro para o número de épocas a serem executadas e perguntar novamente'\n",
    "                    else:\n",
    "                        msg='digite H para interromper o treinamento, F para ajustar o modelo ou um número inteiro para o número de épocas a serem executadas e perguntar novamente'\n",
    "                    print_in_color(msg, (0,255,255), (55,65,80))\n",
    "                    ans=input('')                     \n",
    "                    if ans=='H' or ans=='h':\n",
    "                        msg=f'você digitou H - o treinamento foi interrompido na época {epoch + 1} devido à entrada do usuário'\n",
    "                        print_in_color(msg, (0,255,255), (55,65,80))\n",
    "                        self.model.stop_training = True # parar o treinamento\n",
    "                    elif ans == 'F' or ans=='f':\n",
    "                        if base_model.trainable:\n",
    "                            msg='você digitou F, mas base_model já está definido como treinável'\n",
    "                        else:\n",
    "                            msg='você digitou F - definindo base_model como treinável para ajuste fino do modelo'\n",
    "                            self.base_model.trainable=True\n",
    "                        print_in_color(msg, (0, 255,255), (55,65,80))\n",
    "                        msg='Digite um número inteiro para o número de épocas a serem executadas e depois ser perguntado novamente'\n",
    "                        print_in_color(msg, (0,2555,255), (55,65,80))\n",
    "                        ans=input()\n",
    "                        ans=int(ans)\n",
    "                        self.ask_epoch +=ans\n",
    "                        msg=f' você digitou {ans} o treinamento continuará até a época {self.ask_epoch} '  \n",
    "                        print_in_color(msg, (0, 255,255), (55,65,80))    \n",
    "                        msg='{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^9s}{6:^9s}{7:^10s}{8:^8s}'.format('Epoch', 'Loss', 'Accuracy',\n",
    "                                                                                            'V_loss','V_acc', 'LR', 'Next LR', 'Monitor','% Improv', 'Duration')\n",
    "                        print_in_color(msg, (244,252,3), (55,65,80))                         \n",
    "                        self.count=0\n",
    "                        self.stop_count=0                         \n",
    "                    else:\n",
    "                        ans=int(ans)\n",
    "                        self.ask_epoch +=ans\n",
    "                        msg=f' você digitou {ans} o treinamento continuará até a época {self.ask_epoch} '                        \n",
    "                        print_in_color(msg, (0, 255,255), (55,65,80))\n",
    "                        msg='{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^9s}{6:^9s}{7:^10s}{8:10s}{9:^8s}'.format('Epoch', 'Loss', 'Accuracy',\n",
    "                                                                                            'V_loss','V_acc', 'LR', 'Next LR', 'Monitor','% Improv', 'Duration')\n",
    "                        print_in_color(msg, (244,252,3), (55,65,80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saver(save_path, model, model_name, subject, accuracy,img_size, scalar,offset ,generator):    \n",
    "    # Salvando o modelo\n",
    "    save_id=str (model_name +  '-' + subject +'-'+ str(acc)[:str(acc).rfind('.')+3] + '.h5')\n",
    "    model_save_loc=os.path.join(save_path, save_id)\n",
    "    model.save(model_save_loc)\n",
    "    print_in_color ('model was saved as ' + model_save_loc, (0,255,0),(55,65,80)) \n",
    "    # now create the class_df and convert to csv file    \n",
    "    class_dict=generator.class_indices \n",
    "    height=[]\n",
    "    width=[]\n",
    "    scale=[]\n",
    "    off=[]\n",
    "    for i in range(len(class_dict)):\n",
    "        height.append(img_size[0])\n",
    "        width.append(img_size[1])\n",
    "        scale.append(scalar) \n",
    "        off.append(offset)\n",
    "    Index_series=pd.Series(list(class_dict.values()), name='class_index')\n",
    "    Class_series=pd.Series(list(class_dict.keys()), name='class') \n",
    "    Height_series=pd.Series(height, name='height')\n",
    "    Width_series=pd.Series(width, name='width')\n",
    "    Scale_series=pd.Series(scale, name='scale by')\n",
    "    Off_series=pd.Series(off, name='Offset')\n",
    "    class_df=pd.concat([Index_series, Class_series, Height_series, Width_series, Scale_series, Off_series],axis=1)    \n",
    "    csv_name='class_dict.csv'\n",
    "    csv_save_loc=os.path.join(save_path, csv_name)\n",
    "    class_df.to_csv(csv_save_loc, index=False) \n",
    "    print_in_color ('class csv file was saved as ' + csv_save_loc, (0,255,0),(55,65,80)) \n",
    "    return model_save_loc, csv_save_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(sdir, csv_path,  model_path, averaged=True, verbose=True):    \n",
    "    # read in the csv file\n",
    "    class_df=pd.read_csv(csv_path)    \n",
    "    class_count=len(classes)    \n",
    "    img_size= image_size \n",
    "    scale=1  \n",
    "    # determine value to scale image pixels by\n",
    "    try: \n",
    "        s=int(scale)\n",
    "        s2=1\n",
    "        s1=0\n",
    "    except:\n",
    "        split=scale.split('-')\n",
    "        s1=float(split[1])\n",
    "        s2=float(split[0].split('*')[1])\n",
    "    path_list=[]\n",
    "    paths=os.listdir(sdir)    \n",
    "    for f in paths:\n",
    "        path_list.append(os.path.join(sdir,f))\n",
    "    if verbose:\n",
    "        print (' Model is being loaded- this will take about 10 seconds')\n",
    "    model=load_model(model_path)\n",
    "    image_count=len(path_list) \n",
    "    image_list=[]\n",
    "    file_list=[]\n",
    "    good_image_count=0\n",
    "    for i in range (image_count):        \n",
    "        try:\n",
    "            img=cv2.imread(path_list[i])\n",
    "            img=cv2.resize(img, img_size)\n",
    "            img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)            \n",
    "            good_image_count +=1\n",
    "            img=img*s2 - s1             \n",
    "            image_list.append(img)\n",
    "            file_name=os.path.split(path_list[i])[1]\n",
    "            file_list.append(file_name)\n",
    "        except:\n",
    "            if verbose:\n",
    "                print ( path_list[i], ' is an invalid image file')\n",
    "    if good_image_count==1: # if only a single image need to expand dimensions\n",
    "        averaged=True\n",
    "    image_array=np.array(image_list)    \n",
    "    # make predictions on images, sum the probabilities of each class then find class index with\n",
    "    # highest probability\n",
    "    preds=model.predict(image_array)    \n",
    "    if averaged:\n",
    "        psum=[]\n",
    "        for i in range (class_count): # create all 0 values list\n",
    "            psum.append(0)    \n",
    "        for p in preds: # iterate over all predictions\n",
    "            for i in range (class_count):\n",
    "                psum[i]=psum[i] + p[i]  # sum the probabilities   \n",
    "        index=np.argmax(psum) # find the class index with the highest probability sum        \n",
    "        klass=class_df['class'].iloc[index] # get the class name that corresponds to the index\n",
    "        prob=psum[index]/len(preds) * 100  # get the probability average         \n",
    "        # to show the correct image run predict again and select first image that has same index\n",
    "        for img in image_array:  #iterate through the images    \n",
    "            test_img=np.expand_dims(img, axis=0) # since it is a single image expand dimensions \n",
    "            test_index=np.argmax(model.predict(test_img)) # for this image find the class index with highest probability\n",
    "            if test_index== index: # see if this image has the same index as was selected previously\n",
    "                if verbose: # show image and print result if verbose=1\n",
    "                    plt.axis('off')\n",
    "                    plt.imshow(img) # show the image\n",
    "                    print (f'predicted class is {klass} with a probability of {prob:6.4f} % ')\n",
    "                break # found an image that represents the predicted class      \n",
    "        return klass, prob, img, None\n",
    "    else: # create individual predictions for each image\n",
    "        pred_class=[]\n",
    "        prob_list=[]\n",
    "        for i, p in enumerate(preds):\n",
    "            index=np.argmax(p) # find the class index with the highest probability sum\n",
    "            klass=class_df['class'].iloc[index] # get the class name that corresponds to the index\n",
    "            image_file= file_list[i]\n",
    "            pred_class.append(klass)\n",
    "            prob_list.append(p[index])            \n",
    "        Fseries=pd.Series(file_list, name='image file')\n",
    "        Lseries=pd.Series(pred_class, name= 'class')\n",
    "        Pseries=pd.Series(prob_list, name='probability')\n",
    "        df=pd.concat([Fseries, Lseries, Pseries], axis=1)\n",
    "        if verbose:\n",
    "            length= len(df)\n",
    "            print (df.head(length))\n",
    "        return None, None, None, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    #rescale = 1.0/255,\n",
    "    validation_split = 0.20, # 25% para validação\n",
    "    #shear_range = 0.2, # inclinação\n",
    "    #zoom_range = 0.2, # zoom\n",
    "    horizontal_flip = True # espelhamento horizontal\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11362 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size = image_size,\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    subset = 'training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2838 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size = image_size,\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    subset = 'validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() # instanciando o modelo\n",
    "model.add(Conv2D(32, (3,3), input_shape=(image_size[0], image_size[1], 3), activation='relu')) # camada de convolução\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) # camada de pooling\n",
    "model.add(Conv2D(64, (3,3), activation='relu')) # camada de convolução\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) # camada de pooling\n",
    "model.add(Flatten()) # camada de achatamento ou vetorização\n",
    "model.add(Dense(64, activation='relu')) # neurônios\n",
    "model.add(Dropout(0.6)) # regularização 50% chance de desligar neurônios\n",
    "model.add(Dense(5, activation='softmax')) # camada de saída (classificação binária)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compilar o modelo\n",
    "model.compile(\n",
    "    Adamax(0.001),\n",
    "    loss = 'categorical_crossentropy', # mais próximo de 0 melhor, 0.002 por exemplo\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "285/285 [==============================] - 151s 525ms/step - loss: 11.7350 - accuracy: 0.2698 - val_loss: 1.5661 - val_accuracy: 0.2770\n",
      "Epoch 2/75\n",
      "285/285 [==============================] - 149s 521ms/step - loss: 1.5509 - accuracy: 0.2767 - val_loss: 1.5368 - val_accuracy: 0.2770\n",
      "Epoch 3/75\n",
      "285/285 [==============================] - 148s 521ms/step - loss: 1.5275 - accuracy: 0.2762 - val_loss: 1.5190 - val_accuracy: 0.2833\n",
      "Epoch 4/75\n",
      "285/285 [==============================] - 148s 519ms/step - loss: 1.5134 - accuracy: 0.2834 - val_loss: 1.5081 - val_accuracy: 0.2833\n",
      "Epoch 5/75\n",
      "285/285 [==============================] - 148s 520ms/step - loss: 1.5055 - accuracy: 0.2834 - val_loss: 1.5028 - val_accuracy: 0.2833\n",
      "Epoch 6/75\n",
      "285/285 [==============================] - 148s 520ms/step - loss: 1.5015 - accuracy: 0.2834 - val_loss: 1.4997 - val_accuracy: 0.2833\n",
      "Epoch 7/75\n",
      "285/285 [==============================] - 148s 518ms/step - loss: 1.4990 - accuracy: 0.2834 - val_loss: 1.4977 - val_accuracy: 0.2833\n",
      "Epoch 8/75\n",
      "285/285 [==============================] - 148s 517ms/step - loss: 1.4973 - accuracy: 0.2834 - val_loss: 1.4962 - val_accuracy: 0.2833\n",
      "Epoch 9/75\n",
      "285/285 [==============================] - 147s 517ms/step - loss: 1.4961 - accuracy: 0.2834 - val_loss: 1.4952 - val_accuracy: 0.2833\n",
      "Epoch 10/75\n",
      "285/285 [==============================] - 148s 519ms/step - loss: 1.4952 - accuracy: 0.2834 - val_loss: 1.4944 - val_accuracy: 0.2833\n",
      "Epoch 11/75\n",
      "285/285 [==============================] - 148s 518ms/step - loss: 1.4946 - accuracy: 0.2834 - val_loss: 1.4939 - val_accuracy: 0.2833\n",
      "Epoch 12/75\n",
      "285/285 [==============================] - 147s 517ms/step - loss: 1.4942 - accuracy: 0.2834 - val_loss: 1.4936 - val_accuracy: 0.2833\n",
      "Epoch 13/75\n",
      "285/285 [==============================] - 148s 519ms/step - loss: 1.4940 - accuracy: 0.2834 - val_loss: 1.4935 - val_accuracy: 0.2833\n",
      "Epoch 14/75\n",
      "285/285 [==============================] - 147s 517ms/step - loss: 1.4941 - accuracy: 0.2834 - val_loss: 1.4934 - val_accuracy: 0.2833\n",
      "Epoch 15/75\n",
      "285/285 [==============================] - 148s 519ms/step - loss: 1.4938 - accuracy: 0.2834 - val_loss: 1.4933 - val_accuracy: 0.2833\n",
      "Epoch 16/75\n",
      "285/285 [==============================] - 147s 517ms/step - loss: 1.4937 - accuracy: 0.2834 - val_loss: 1.4932 - val_accuracy: 0.2833\n",
      "Epoch 17/75\n",
      "285/285 [==============================] - 147s 516ms/step - loss: 1.4937 - accuracy: 0.2834 - val_loss: 1.4932 - val_accuracy: 0.2833\n",
      "Epoch 18/75\n",
      "285/285 [==============================] - 147s 516ms/step - loss: 1.4936 - accuracy: 0.2834 - val_loss: 1.4932 - val_accuracy: 0.2833\n",
      "Epoch 19/75\n",
      "285/285 [==============================] - 149s 521ms/step - loss: 1.4936 - accuracy: 0.2834 - val_loss: 1.4932 - val_accuracy: 0.2833\n",
      "Epoch 20/75\n",
      "285/285 [==============================] - 148s 518ms/step - loss: 1.4936 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 21/75\n",
      "285/285 [==============================] - 147s 517ms/step - loss: 1.4936 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 22/75\n",
      "285/285 [==============================] - 147s 517ms/step - loss: 1.4936 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 23/75\n",
      "285/285 [==============================] - 149s 523ms/step - loss: 1.4936 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 24/75\n",
      "285/285 [==============================] - 148s 519ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 25/75\n",
      "285/285 [==============================] - 148s 519ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 26/75\n",
      "285/285 [==============================] - 148s 518ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 27/75\n",
      "285/285 [==============================] - 147s 514ms/step - loss: 1.4936 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 28/75\n",
      "285/285 [==============================] - 148s 518ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 29/75\n",
      "285/285 [==============================] - 148s 519ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 30/75\n",
      "285/285 [==============================] - 147s 516ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 31/75\n",
      "285/285 [==============================] - 148s 518ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 32/75\n",
      "285/285 [==============================] - 148s 519ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 33/75\n",
      "285/285 [==============================] - 147s 517ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 34/75\n",
      "285/285 [==============================] - 148s 518ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 35/75\n",
      "285/285 [==============================] - 148s 519ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 36/75\n",
      "285/285 [==============================] - 148s 517ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 37/75\n",
      "285/285 [==============================] - 149s 521ms/step - loss: 1.4936 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 38/75\n",
      "285/285 [==============================] - 150s 526ms/step - loss: 1.4936 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 39/75\n",
      "285/285 [==============================] - 150s 525ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 40/75\n",
      "285/285 [==============================] - 151s 528ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 41/75\n",
      "285/285 [==============================] - 150s 526ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 42/75\n",
      "285/285 [==============================] - 149s 523ms/step - loss: 1.4936 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 43/75\n",
      "285/285 [==============================] - 151s 529ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 44/75\n",
      "285/285 [==============================] - 148s 520ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 45/75\n",
      "285/285 [==============================] - 148s 520ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 46/75\n",
      "285/285 [==============================] - 148s 519ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 47/75\n",
      "285/285 [==============================] - 148s 520ms/step - loss: 1.4936 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 48/75\n",
      "285/285 [==============================] - 148s 519ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 49/75\n",
      "285/285 [==============================] - 148s 519ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 50/75\n",
      "285/285 [==============================] - 148s 519ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 51/75\n",
      "285/285 [==============================] - 148s 520ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 52/75\n",
      "285/285 [==============================] - 148s 518ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 53/75\n",
      "285/285 [==============================] - 148s 517ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 54/75\n",
      "285/285 [==============================] - 147s 517ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 55/75\n",
      "285/285 [==============================] - 148s 519ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 56/75\n",
      "285/285 [==============================] - 148s 519ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 57/75\n",
      "285/285 [==============================] - 148s 519ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 58/75\n",
      "285/285 [==============================] - 147s 517ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 59/75\n",
      "285/285 [==============================] - 148s 518ms/step - loss: 1.4936 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 60/75\n",
      "285/285 [==============================] - 147s 516ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 61/75\n",
      "285/285 [==============================] - 148s 518ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 62/75\n",
      "285/285 [==============================] - 148s 517ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 63/75\n",
      "285/285 [==============================] - 148s 518ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 64/75\n",
      "285/285 [==============================] - 148s 518ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 65/75\n",
      "285/285 [==============================] - 148s 518ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 66/75\n",
      "285/285 [==============================] - 155s 544ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 67/75\n",
      "285/285 [==============================] - 152s 533ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 68/75\n",
      "285/285 [==============================] - 144s 504ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 69/75\n",
      "285/285 [==============================] - 143s 502ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 70/75\n",
      "285/285 [==============================] - 144s 504ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 71/75\n",
      "285/285 [==============================] - 145s 509ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 72/75\n",
      "285/285 [==============================] - 143s 502ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 73/75\n",
      "285/285 [==============================] - 145s 508ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 74/75\n",
      "285/285 [==============================] - 143s 503ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Epoch 75/75\n",
      "285/285 [==============================] - 143s 502ms/step - loss: 1.4935 - accuracy: 0.2834 - val_loss: 1.4931 - val_accuracy: 0.2833\n",
      "Treinamento concluído!\n"
     ]
    }
   ],
   "source": [
    "# treinamento\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs = num_epochs,\n",
    "    validation_data = validation_generator\n",
    ")\n",
    "\n",
    "print('Treinamento concluído!')\n",
    "\n",
    "# salvar o modelo\n",
    "model.save('./models/ceMod4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
